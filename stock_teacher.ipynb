{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from crewai_tools import SpiderTool, SerperDevTool, ScrapeWebsiteTool, WebsiteSearchTool, SeleniumScrapingTool\n",
    "from crewai import Agent, Task, Crew\n",
    "from utils import get_openai_api_key, get_serper_api_key, get_spider_api_key\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import warnings\n",
    "\n",
    "# Warning control\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "# Set OpenAI API key and model name\n",
    "openai_api_key = get_openai_api_key()\n",
    "os.environ[\"OPENAI_MODEL_NAME\"] = 'gpt-4o'\n",
    "os.environ[\"SERPER_API_KEY\"] = get_serper_api_key()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Initialize tools\n",
    "docs_scrape_tool = ScrapeWebsiteTool()\n",
    "website_search_tool = WebsiteSearchTool()\n",
    "spider_tool = SpiderTool()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "spider_tool = SpiderTool()\n",
    "\n",
    "searcher = Agent(\n",
    "    role=\"Web Research Expert\",\n",
    "    goal=\"\"\"Find related information from specific URL's.\n",
    "          if you are to use the spider tool use the  the input format as below \n",
    "          \n",
    "          \n",
    "    ```      tool_input = {\n",
    "    \"url\": \"url of site\",\n",
    "    \"params\": {\n",
    "        \"limit\": 1,\n",
    "        \"metadata\": True\n",
    "    },\n",
    "    \"mode\": \"scrape\"\n",
    "}```\n",
    "          \n",
    "          \n",
    "          \"\"\",\n",
    "    backstory=\"An expert web researcher that uses the web extremely well\",\n",
    "    tools=[spider_tool],\n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "return_metadata = Task(\n",
    "    description=\"Scrape {website} with a limit of 3 and extract all technical data\",\n",
    "    expected_output=\"all technical data from the website scraped in markdown format\",\n",
    "    agent=searcher\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-10 23:43:47,535 - 129395164063232 - __init__.py-__init__:537 - WARNING: Overriding of current TracerProvider is not allowed\n"
     ]
    }
   ],
   "source": [
    "\n",
    "crew = Crew(\n",
    "        agents=[searcher],\n",
    "        tasks=[\n",
    "            return_metadata,\n",
    "        ],\n",
    "        verbose=True\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'\\n    \"url\"'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[28], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# Define the website variable\u001b[39;00m\n\u001b[1;32m      3\u001b[0m websiteX \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://github.com/crewAIInc/crewAI\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m----> 5\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mcrew\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkickoff\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mwebsite\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mwebsiteX\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/crewai/lib/python3.11/site-packages/crewai/crew.py:524\u001b[0m, in \u001b[0;36mCrew.kickoff\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m    522\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m inputs \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    523\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_inputs \u001b[38;5;241m=\u001b[39m inputs\n\u001b[0;32m--> 524\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_interpolate_inputs\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    525\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_set_tasks_callbacks()\n\u001b[1;32m    527\u001b[0m i18n \u001b[38;5;241m=\u001b[39m I18N(prompt_file\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprompt_file)\n",
      "File \u001b[0;32m~/miniconda3/envs/crewai/lib/python3.11/site-packages/crewai/crew.py:1057\u001b[0m, in \u001b[0;36mCrew._interpolate_inputs\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   1055\u001b[0m \u001b[38;5;66;03m# type: ignore # \"interpolate_inputs\" of \"Agent\" does not return a value (it only ever returns None)\u001b[39;00m\n\u001b[1;32m   1056\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m agent \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39magents:\n\u001b[0;32m-> 1057\u001b[0m     \u001b[43magent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minterpolate_inputs\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/crewai/lib/python3.11/site-packages/crewai/agents/agent_builder/base_agent.py:280\u001b[0m, in \u001b[0;36mBaseAgent.interpolate_inputs\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m    278\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m inputs:\n\u001b[1;32m    279\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrole \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_original_role\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39minputs)\n\u001b[0;32m--> 280\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgoal \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_original_goal\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mformat\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    281\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbackstory \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_original_backstory\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39minputs)\n",
      "\u001b[0;31mKeyError\u001b[0m: '\\n    \"url\"'"
     ]
    }
   ],
   "source": [
    "\n",
    "# Define the website variable\n",
    "websiteX = \"https://github.com/crewAIInc/crewAI\"\n",
    "\n",
    "result = crew.kickoff(inputs={\"website\": websiteX})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from IPython.display import Markdown\n",
    "Markdown(result.raw)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "crewai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
